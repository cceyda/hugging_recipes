{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add a faiss index to your datasets\n",
    "https://huggingface.co/docs/datasets/faiss_es#faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers faiss-cpu >> /dev/null\n",
    "# faiss-cpu pip package is not official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset=load_dataset(\"huggan/smithsonian_butterflies_subset\") # any dataset you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any model you want, also look at feature extraction pipelines!\n",
    "# This example is with images but you can embed anything! just pick your model\n",
    "from transformers import BeitFeatureExtractor, BeitModel\n",
    "feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224')\n",
    "model = BeitModel.from_pretrained('microsoft/beit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the function this way we can use it also during query time\n",
    "def embed(images):\n",
    "    inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs,output_hidden_states= True)\n",
    "    final_emb=outputs.pooler_output.detach().numpy() # this line depends on the model you are using\n",
    "    return final_emb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to dataset\n",
    "dataset_emb = dataset.map(lambda x: {\"beit_embeddings\":embed(x[\"image\"])},batched=True,batch_size=20)\n",
    "dataset_emb.add_faiss_index(column='beit_embeddings')\n",
    "dataset_emb.save_faiss_index('beit_embeddings', 'beit_index.faiss') # (optional) save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just load from disk skip the .map cell above\n",
    "# dataset.load_faiss_index('beit_embeddings', 'beit_index.faiss')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query\n",
    "query_image=dataset[0][\"image\"]\n",
    "scores, result_k=dataset_emb.get_nearest_examples('beit_embeddings', embed(query_image), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "from IPython.display import display\n",
    "for x in result_k[\"image\"]:\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you werent using datasets faiss support you would have to do it like the below cells:\n",
    "there maybe better ways but this is what I was doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def embed(ex, idx=None, add_index=True): # Ugh, how ugly!\n",
    "    if add_index:\n",
    "        images = ex[\"image\"]\n",
    "    else:\n",
    "        images = ex\n",
    "    inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs,output_hidden_states= True)\n",
    "    final_emb=outputs.pooler_output.detach().numpy()\n",
    "    \n",
    "    if add_index:\n",
    "        ex['idx'] = idx\n",
    "        index.add(final_emb)                  # add vectors to the index\n",
    "    else: \n",
    "        dist,idx=index.search(final_emb,idx) \n",
    "        return dist,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= 768\n",
    "index = faiss.IndexFlatL2(d)   # build the index\n",
    "print(index.is_trained)\n",
    "dataset=dataset.map(embed,batched=True,batch_size=20,with_indices=True)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image=dataset[3]\n",
    "distances,res_ids=embed(query_image['image'],5,add_index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
